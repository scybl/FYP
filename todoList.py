# Question: 针对于肠息肉数据,色彩信息能够提供一定的分割信息，
# 但是相比之下，肠息肉的形状、纹理信息对于分割而言则是更加重要的特征来源。

# TODO：使用transunet的数据集加载来获取数据集
# TODO：学习transunet的enocder部分, 作一下encoder的部分，调用一个预训练模型

# Poly Strategy, H2Former，
# warmup, 训练 K 轮之后，lr再降低，
# Spark: https://github.com/keyu-tian/SparK/blob/main/pretrain/utils/lr_control.py, warm-up 锁定，K轮次之后再降低lr
# TODO: 深度监督的处理方法
# TODO: 添加一个划分验证集，测试集，训练集的方法，根据config的配置来划分
# TODO: 修复test class
# TODO: 最近发现针对于分割任务,他的边缘问题应该着重注意,边缘平滑,边缘模糊问题对于模型影响很大
# TODO: kvasir和clinicDB数据集训练出来结果全黑,需要完整训练测试
"""
数据质量问题：数据集中可能存在噪音、图像质量差或者标签不准确等问题，这会导致模型学习到错误的特征或者无法正确学习到目标结构。
数据量不足：神经网络通常需要大量的数据来学习复杂的模式和特征。如果数据集太小，模型可能无法充分泛化，导致过拟合或者欠拟合问题。
标签不准确：标签错误或不准确会导致模型学习到错误的分割边界或特征。因此，确保标签准确性非常重要。
网络架构选择不当：选择合适的网络架构对于任务的成功至关重要。对于分割任务，例如语义分割或实例分割，通常使用的网络结构有 U-Net、Mask R-CNN 等。选择与问题匹配的网络架构可以提高模型性能。
数据不平衡：如果数据集中正例和负例之间的分布不平衡，模型可能会倾向于预测更常见的类别，而忽略较少出现的类别。这可能导致模型在预测罕见类别时性能下降。
数据预处理不当：数据预处理是非常重要的一步，它可以影响模型的性能。例如，图像尺寸的标准化、数据增强、图像配准等预处理步骤可以提高模型的鲁棒性和泛化能力。
超参数选择不当：神经网络中的超参数如学习率、优化器、损失函数等选择都会影响模型的性能。通过对这些超参数进行调优可以提高模型的性能。
迁移学习：有时候，从预训练的模型中初始化参数并进行微调可能会比从头开始训练更加有效。通过迁移学习，可以利用在大型数据集上预训练的模型的特征表示来提高模型性能。
"""

# 进度
# TODO: 查看h5文件,在终端输入vitables,然后打开文件(已解决)
# TODO：更改学习率的部分，这里有问题,(已解决)
# 制作一个line table来说明这个
